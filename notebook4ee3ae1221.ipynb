{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U bitsandbytes \n!pip install -U transformers \n!pip install -U accelerate \n!pip install -U peft\n!pip install -U trl\n!pip install -U datasets\n\n\nimport os\nimport torch\nimport wandb\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    BitsAndBytesConfig, \n    TrainingArguments, \n    logging\n)\nfrom peft import LoraConfig, get_peft_model\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom trl import SFTTrainer, setup_chat_format\nimport bitsandbytes as bnb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:03:12.973387Z","iopub.execute_input":"2024-11-11T02:03:12.974050Z","iopub.status.idle":"2024-11-11T02:05:05.144369Z","shell.execute_reply.started":"2024-11-11T02:03:12.974012Z","shell.execute_reply":"2024-11-11T02:05:05.143361Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"huggingface\")\nlogin(token=hf_token)\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(project='Fine-tune Gemma-2-2b-it Doctor', job_type=\"training\", anonymous=\"allow\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:05:45.709273Z","iopub.execute_input":"2024-11-11T02:05:45.710629Z","iopub.status.idle":"2024-11-11T02:05:50.275151Z","shell.execute_reply.started":"2024-11-11T02:05:45.710584Z","shell.execute_reply":"2024-11-11T02:05:50.274355Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvattvoltamper\u001b[0m (\u001b[33mvattvoltamper-ustudy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111304434444441, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d23c205fc3234f06b0556608c1d208fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241111_020546-7yn63fv9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset/runs/7yn63fv9' target=\"_blank\">feasible-yogurt-3</a></strong> to <a href='https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset/runs/7yn63fv9' target=\"_blank\">https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset/runs/7yn63fv9</a>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"base_model = \"google/gemma-2-2b-it\"\nnew_model = \"Gemma-2-2b-it-ChatDoctor\"\ndataset_name = \"lavita/ChatDoctor-HealthCareMagic-100k\"\n\nif torch.cuda.get_device_capability()[0] >= 8:\n    torch_dtype = torch.bfloat16\n    attn_implementation = \"flash_attention_2\" # !pip install -qqq flash-attn\nelse:\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:06:12.542631Z","iopub.execute_input":"2024-11-11T02:06:12.543312Z","iopub.status.idle":"2024-11-11T02:06:12.552432Z","shell.execute_reply.started":"2024-11-11T02:06:12.543273Z","shell.execute_reply":"2024-11-11T02:06:12.551662Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install trl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            if len(names) == 1:\n                lora_module_names.add(names[0])\n            else:\n                lora_module_names.add(names[-1])\n    lora_module_names.discard('lm_head')  \n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:06:33.883924Z","iopub.execute_input":"2024-11-11T02:06:33.884596Z","iopub.status.idle":"2024-11-11T02:08:47.642827Z","shell.execute_reply.started":"2024-11-11T02:06:33.884553Z","shell.execute_reply":"2024-11-11T02:08:47.642058Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0648f2db1be4531bc30c92fb32a3148"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb9d3a4330984807bbf1aacc535634b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f9627a6518e4d9295af958995e420f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ac068788274ab3afde48449634ff5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04c0af70dbb64ae4a33f75c394b37840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47373c9740274b25b727aced5a7126c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e03f810bcf3400394ff706562bea808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f418c3a06f34ce2bdc800af3a00aba2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f70070fb7aa4f09b417347a569d673e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"995a8f8ec3524230a32da9b00eb741a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74cfe9a33c743ceb9d0dca819e0ec20"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)\n\ntokenizer.chat_template = None \n\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = get_peft_model(model, peft_config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:10:39.377824Z","iopub.execute_input":"2024-11-11T02:10:39.378278Z","iopub.status.idle":"2024-11-11T02:10:42.830942Z","shell.execute_reply.started":"2024-11-11T02:10:39.378239Z","shell.execute_reply":"2024-11-11T02:10:42.829929Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import re\nfrom datasets import load_dataset\n\n\ndataset = load_dataset(dataset_name, split=\"all\", cache_dir=\"./cache\")\ndataset = dataset.shuffle(seed=42).select(range(2000))  \n\ndef clean_text(text):\n    text = re.sub(r'\\b(?:www\\.[^\\s]+|http\\S+)', '', text)                   # Remove URLs\n    text = re.sub(r'\\b(?:aCht Doctor(?:.com)?(?:.in)?|www\\.(?:google|yahoo)\\S*)', '', text)  # Remove site names\n    text = re.sub(r'\\s+', ' ', text)                                    \n    return text.strip()\n\ndef format_chat_template(row):\n    cleaned_instruction = clean_text(row[\"instruction\"])\n    cleaned_input = clean_text(row[\"input\"])\n    cleaned_output = clean_text(row[\"output\"])\n    \n    row_json = [\n        {\"role\": \"system\", \"content\": cleaned_instruction},\n        {\"role\": \"user\", \"content\": cleaned_input},\n        {\"role\": \"assistant\", \"content\": cleaned_output}\n    ]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(format_chat_template, num_proc=4)\n\ndataset = dataset.train_test_split(test_size=0.1)\ndata_collator = lambda batch: tokenizer(batch[\"text\"], return_tensors=\"pt\", padding=True, truncation=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:11:14.481365Z","iopub.execute_input":"2024-11-11T02:11:14.481782Z","iopub.status.idle":"2024-11-11T02:11:19.808909Z","shell.execute_reply.started":"2024-11-11T02:11:14.481746Z","shell.execute_reply":"2024-11-11T02:11:19.808029Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/542 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b3662dd5fc4493ba174f657511b3a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-5e7cb295b9cff0bf.parquet:   0%|          | 0.00/70.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bebe9692c06d49fb87ce8d0b0845548f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/112165 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50688ef48df44cd085a7953e03c3a8b1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50b54ca1db6b494eb712f1a85477ea9a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n    num_train_epochs=1,\n    eval_strategy=\"steps\",\n    eval_steps=200, \n    save_steps=500,  \n    logging_steps=1,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=0.0002,\n    fp16=True,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\",\n    load_best_model_at_end=False \n)\n\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    peft_config=peft_config,\n    max_seq_length=512,\n    dataset_text_field=\"text\",  \n    tokenizer=tokenizer,\n    args=training_args,\n    packing=False,\n)\n\nmodel.config.use_cache = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:11:46.116604Z","iopub.execute_input":"2024-11-11T02:11:46.117328Z","iopub.status.idle":"2024-11-11T02:11:49.750146Z","shell.execute_reply.started":"2024-11-11T02:11:46.117281Z","shell.execute_reply":"2024-11-11T02:11:49.749295Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e758f2917c0425392f9ac919185f151"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7623ffa92334cef81cc469865b8dbbc"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:12:14.815616Z","iopub.execute_input":"2024-11-11T02:12:14.816016Z","iopub.status.idle":"2024-11-11T02:37:15.464978Z","shell.execute_reply.started":"2024-11-11T02:12:14.815978Z","shell.execute_reply":"2024-11-11T02:37:15.464099Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [900/900 24:56, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>2.271000</td>\n      <td>2.578353</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.217100</td>\n      <td>2.522850</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.416100</td>\n      <td>2.488086</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.743400</td>\n      <td>2.464270</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=900, training_loss=2.5062590618928273, metrics={'train_runtime': 1499.4907, 'train_samples_per_second': 1.2, 'train_steps_per_second': 0.6, 'total_flos': 5615864755831296.0, 'train_loss': 2.5062590618928273, 'epoch': 1.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:37:40.932983Z","iopub.execute_input":"2024-11-11T02:37:40.933795Z","iopub.status.idle":"2024-11-11T02:37:42.492500Z","shell.execute_reply.started":"2024-11-11T02:37:40.933754Z","shell.execute_reply":"2024-11-11T02:37:42.491686Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.029 MB of 0.029 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a1d64909274836ac3e6b1060ff2123"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▂▁</td></tr><tr><td>eval/runtime</td><td>█▁▅▄</td></tr><tr><td>eval/samples_per_second</td><td>▁█▅▅</td></tr><tr><td>eval/steps_per_second</td><td>▁█▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▅▆▃▄▃▂▄▅▄▄▄▂▅▁▄▂▂▄▃▅▃▄▅▂▄█▃▃▄▄▂▃▄▃▂▄▃▅▄▅</td></tr><tr><td>train/learning_rate</td><td>▃████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>▆▅█▅▄▆▃▁▅▃▆▆▆▅▅▄▃▇▄▃▆▄▄▄▁▆▄▆▅▄▄▃▆▇▃▃▅▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.46427</td></tr><tr><td>eval/runtime</td><td>62.1611</td></tr><tr><td>eval/samples_per_second</td><td>3.217</td></tr><tr><td>eval/steps_per_second</td><td>3.217</td></tr><tr><td>total_flos</td><td>5615864755831296.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>900</td></tr><tr><td>train/grad_norm</td><td>2.1567</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>2.6493</td></tr><tr><td>train_loss</td><td>2.50626</td></tr><tr><td>train_runtime</td><td>1499.4907</td></tr><tr><td>train_samples_per_second</td><td>1.2</td></tr><tr><td>train_steps_per_second</td><td>0.6</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">feasible-yogurt-3</strong> at: <a href='https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset/runs/7yn63fv9' target=\"_blank\">https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset/runs/7yn63fv9</a><br/> View project at: <a href='https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/vattvoltamper-ustudy/Fine-tune%20Gemma-2-2b-it%20on%20Medical%20Dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241111_020546-7yn63fv9/logs</code>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import GenerationConfig\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a medical expert specializing in respiratory diseases.\"},\n    {\"role\": \"user\", \"content\": \"I have a persistent cough, night sweats, and recent weight loss. I’ve been to multiple doctors with no diagnosis yet. Could these symptoms be related to tuberculosis or another serious illness? Please provide a detailed answer considering possible causes and recommended next steps.\"}\n]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(\n    **inputs,\n    max_length=350,          \n    top_k=50,                \n    top_p=0.85,               \n    temperature=0.3,         \n    no_repeat_ngram_size=3,  \n)\n\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"assistant\")[-1].strip()\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T02:38:58.668950Z","iopub.execute_input":"2024-11-11T02:38:58.669363Z","iopub.status.idle":"2024-11-11T02:39:39.699391Z","shell.execute_reply.started":"2024-11-11T02:38:58.669326Z","shell.execute_reply":"2024-11-11T02:39:39.698420Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.85` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Hi, Thanks for writing to us. I have gone through your query and understand your concern. I would like to tell you that the symptoms you have mentioned are suggestive of tuberculosis. I suggest you to consult a pulmonologist and get done a chest x-ray and sputum examination. If the chest x -ray is suggestive of TB, then you should get done sputum culture and sensitivity test. If it is positive, then it is confirmed that you have TB. You should take anti-TB treatment under the supervision of a pulmonology. I hope this information would help you. Please do not hesitate to ask in case of any further doubts. Thanks and regards. Wish you a good health. . N. Senior Surgical Specialist. . S. Genl-CVTS. . M.S. . D.N.B.S, D.C.S(S). . F.C.(S). Wish you good health and a long life. . . N, Senior Surgical specialist. .S. Gen. CVTS. M. S. D. N. B. S, D C S (S) F. C. (S). Thanks and Regards. Wish You Good Health and a Long Life. .N. Senior surgical specialist. S Genl CVTS M.s D.n.B S D.c.S (S),\n","output_type":"stream"}],"execution_count":12}]}